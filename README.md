# ğŸ¾ Human & Animal Detection â€“ Offline Vision System

## ğŸ“Œ Project Overview

This project implements a fully offline **Human & Animal Detection system** using:

- âœ… Custom Convolutional Neural Network (CNN)
- âœ… Haar Cascade (Human face detection)
- âœ… Selective Search (Animal region proposals)
- âœ… Streamlit Web Application
- âœ… Standalone Inference Script (`main.py`)
- âŒ No YOLO
- âŒ No COCO / ImageNet training datasets
- âŒ No cloud-based APIs

The system detects and classifies Humans and Animals in images using classical computer vision combined with deep learning.

---

```bash
project/
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ train/
â”‚       â”œâ”€â”€ human/
â”‚       â””â”€â”€ animal/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ classifier.pth
â”œâ”€â”€ test_videos/
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ output_image.jpg
â”‚   â””â”€â”€ sample_output.json
â”œâ”€â”€ main.py
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```
---

# ğŸ§  Dataset Justification

### Why NOT COCO?
- COCO is a large-scale object detection dataset with 80+ classes.
- Requires bounding box annotations.
- Heavy and unnecessary for binary classification.
- Violates assignment constraint.

### Why NOT ImageNet?
- Generic multi-class dataset.
- Heavy pretrained dependency.
- Not optimized for Human vs Animal binary task.

### Why Custom Dataset?
- Focused binary classification (Human vs Animal).
- Lightweight and controlled.
- Balanced classes.
- Fully offline training.
- Faster experimentation and debugging.

Dataset Format:
datasets/train/human/
datasets/train/animal/


---

# ğŸ§  Model Selection Justification

Selected Model: **Custom CNN**

Reasons:
- Lightweight architecture
- Fast training
- Low memory usage
- CPU compatible
- No internet dependency
- Suitable for binary classification

Architecture:
- 3 Convolution layers
- ReLU activation
- MaxPooling
- Fully connected layers
- Sigmoid output

Loss Function:
Binary Cross Entropy (BCELoss)


Optimizer:
Adam (lr = 0.001)


Epochs:
10


YOLO was avoided because:
- Prohibited in assignment
- Heavy detection model
- Unnecessary complexity

---

# âš™ï¸ Training Process

1. Images resized to 128x128
2. Normalization applied
3. Loaded using PyTorch ImageFolder
4. Batch size = 16
5. Trained for 10 epochs
6. Model saved as:

models/classifier.pth


---

# ğŸ” Inference Pipeline (Step-by-Step)

Implemented in both:

- `main.py` â†’ Command Line Inference
- `app.py` â†’ Streamlit Web UI

### Step 1: Human Detection
- Uses OpenCV Haar Cascade
- Detects faces in image

### Step 2: Animal Region Proposals
- Uses Selective Search
- Generates candidate regions

### Step 3: Classification
Each detected region:
- Resized to 128x128
- Normalized
- Passed through CNN
- Threshold applied:
  - prob > 0.7 â†’ Human
  - prob < 0.3 â†’ Animal

### Step 4: Output Generation
- Bounding boxes drawn
- Image saved in `/outputs/`
- JSON structured output generated

---

# ğŸ“Š Evaluation Metrics

For classification:

- Accuracy
- Precision
- Recall
- F1 Score

For detection (if extended):

- mAP@0.5 (Mean Average Precision)
- IoU threshold = 0.5

mAP is mentioned for completeness as standard detection evaluation metric.

---

# ğŸ”’ Offline Compliance

- No YOLO
- No COCO dataset
- No ImageNet dependency
- No Cloud APIs
- No internet required
- No runtime model downloads

All models load locally from:
models/classifier.pth


---

# ğŸ’» Hardware Constraints

Minimum Requirements:

- 8GB RAM
- Intel i5 or equivalent
- CPU supported
- GPU optional (auto-detected)

Optimizations:

- Image resizing (128x128)
- Lightweight CNN
- Limited region proposals
- Batch size control

System is designed to work in low-resource offline environments.

---

# âš™ï¸ Installation Instructions

## Step 1: Create Virtual Environment (Recommended)

python -m venv venv


Activate:

Windows:
venv\Scripts\activate


Mac/Linux:
source venv/bin/activate


---

## Step 2: Install Dependencies

pip install -r requirements.txt


---

## Step 3: Ensure Dataset Exists

datasets/train/human/
datasets/train/animal/


---

# ğŸš€ Running the Application

## Option 1: Run Streamlit App

streamlit run app.py


Upload an image and click **Run Detection**.

Output saved to:
outputs/output_image.jpg


---

## Option 2: Run Inference via CLI

python main.py


Outputs will be saved in:
outputs/


---

# ğŸ“¦ Sample Output (JSON Format)

Example `sample_output.json`:

```json
{
  "file_name": "sample_image.jpg",
  "detections": [
    {
      "label": "Human",
      "confidence": 0.91
    },
    {
      "label": "Animal",
      "confidence": 0.87
    }
  ]
}
âš ï¸ Important Notes
Requires opencv-contrib-python for Selective Search.

First run may train model if classifier.pth does not exist.
However the classifier.pth model ğŸ”—link is provided in 
models folderğŸ“ --> classifier_drive_path.pth ğŸ“

Training time: 2â€“5 minutes on CPU.

ğŸ§© Challenges Faced
False positives from selective search

Threshold tuning for binary classification

Avoiding heavy detection frameworks

Maintaining full offline functionality

CPU performance optimization

ğŸ”® Possible Improvements
Add Non-Maximum Suppression (NMS)

Add bounding box evaluation with mAP

Add video frame-by-frame detection

Improve dataset diversity

Add confusion matrix visualization

ğŸ‘©â€ğŸ’» Author
Human & Animal Detection â€“ Offline Vision System
Assignment Submission


---

If you want, I can also generate:

- ğŸ“„ Professional Documentation (DOC/PDF content)
- ğŸ“¦ Final Submission Checklist Summary
- â­ GitHub-ready version with badges and formatting

Just tell me.
